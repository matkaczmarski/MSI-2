\providecommand{\bbobECDFslegend}[1]{
Bootstrapped empirical cumulative distribution of the number of objective function evaluations divided by dimension (FEvals/DIM) for 50 targets in $10^{[-8..2]}$ for all functions and subgroups in #1-D. The ``best 2009'' line corresponds to the best \ERT\ observed during BBOB 2009 for each single target.
}
\providecommand{\bbobppfigslegend}[1]{
Expected running time (\ERT\ in number of $f$-evaluations 
                as $\log_{10}$ value), divided by dimension for target function value $10^{-8}$ 
                versus dimension. Slanted grid lines indicate quadratic scaling with the dimension. Different symbols correspond to different algorithms given in the legend of #1. Light symbols give the maximum number of function evaluations from the longest trial divided by dimension. Black stars indicate a statistically better result compared to all other algorithms with $p<0.01$ and Bonferroni correction number of dimensions (six).  
Legend: 
{\color{NavyBlue}$\circ$}:\algorithmA
, {\color{red}$\triangledown$}:\algorithmB
, {\color{Goldenrod}$\star$}:\algorithmC
, {\color{VioletRed}$\Box$}:\algorithmD
}
\providecommand{\bbobpptablesmanylegend}[1]{%
    Expected running time (ERT in number of function 
    evaluations) divided by the respective best ERT measured during BBOB-2009 in
    #1.
    The ERT and in braces, as dispersion measure, the half difference between 90 and 
    10\%-tile of bootstrapped run lengths appear for each algorithm and 
    %
    target, the corresponding best ERT
    in the first row. The different target \Df-values are shown in the top row. 
    \#succ is the number of trials that reached the (final) target $\fopt + 10^{-8}$.
    %
    The median number of conducted function evaluations is additionally given in 
    \textit{italics}, if the target in the last column was never reached. 
    Entries, succeeded by a star, are statistically significantly better (according to
    the rank-sum test) when compared to all other algorithms of the table, with
    $p = 0.05$ or $p = 10^{-k}$ when the number $k$ following the star is larger
    than 1, with Bonferroni correction by the number of instances.
    }
\providecommand{\algorithmA}{PSO DE}
\providecommand{\algorithmB}{PSO DE modified}
\providecommand{\algorithmC}{PSO DE with Resets}
\providecommand{\algorithmD}{DE}
\providecommand{\bbobECDFslegend}[1]{
Bootstrapped empirical cumulative distribution of the number of objective function evaluations divided by dimension (FEvals/DIM) for 50 targets in $10^{[-8..2]}$ for all functions and subgroups in #1-D. The ``best 2009'' line corresponds to the best \ERT\ observed during BBOB 2009 for each single target.
}
\providecommand{\bbobppfigslegend}[1]{
Expected running time (\ERT\ in number of $f$-evaluations 
                as $\log_{10}$ value), divided by dimension for target function value $10^{-8}$ 
                versus dimension. Slanted grid lines indicate quadratic scaling with the dimension. Different symbols correspond to different algorithms given in the legend of #1. Light symbols give the maximum number of function evaluations from the longest trial divided by dimension. Black stars indicate a statistically better result compared to all other algorithms with $p<0.01$ and Bonferroni correction number of dimensions (six).  
Legend: 
{\color{NavyBlue}$\circ$}:\algorithmA
, {\color{red}$\triangledown$}:\algorithmB
}
\providecommand{\bbobppscatterlegend}[1]{
Expected running time (\ERT\ in $\log_{10}$ of number of function evaluations) 
    of \algorithmB\ ($x$-axis) versus \algorithmA\ ($y$-axis) for $46$ target values 
    $\Df \in [100, 10^{-8}]$ in each dimension on functions #1. Markers on the upper or right edge indicate that the respective target
    value was never reached. Markers represent dimension: 
    2:{\color{cyan}+}, 
    3:{\color{green!45!black}$\triangledown$}, 
    5:{\color{blue}$\star$}, 
    10:$\circ$,
    20:{\color{red}$\Box$}, 
    40:{\color{magenta}$\Diamond$}. 
}
\providecommand{\bbobpptablestwolegend}[1]{
%
    Expected running time (ERT in number of function 
    evaluations) divided by the respective best ERT measured during BBOB-2009 in
    dimensions 5 (left) and 20 (right).
    The ERT and in braces, as dispersion measure, the half difference between 90 and 
    10\%-tile of bootstrapped run lengths appear for each algorithm and 
    %
    target, the corresponding best ERT
    in the first row. The different target \Df-values are shown in the top row. 
    \#succ is the number of trials that reached the (final) target $\fopt + 10^{-8}$.
    %
    The median number of conducted function evaluations is additionally given in 
    \textit{italics}, if the target in the last column was never reached. 
    1:\algorithmAshort\ is \algorithmA\ and 2:\algorithmBshort\ is \algorithmB.
    Bold entries are statistically significantly better compared to the other algorithm,
    with $p=0.05$ or $p=10^{-k}$ where $k\in\{2,3,4,\dots\}$ is the number
    following the $\star$ symbol, with Bonferroni correction of #1.
    A $\downarrow$ indicates the same tested against the best algorithm of BBOB-2009.
    
}
\providecommand{\bbobpprldistrlegendtwo}[1]{
%
    Empirical cumulative distributions (ECDF)
    of run lengths and speed-up ratios in 5-D (left) and 20-D (right).
    Left sub-columns: ECDF of
    the number of function evaluations divided by dimension $D$
    (FEvals/D) %
    to reach a target value $\fopt+\Df$ with $\Df=10^{k}$, where
    $k\in\{1, -1, -4, -8\}$ is given by the first value in the legend, for
    \algorithmA\ ($\circ$) and \algorithmB\ ($\triangledown$). Light beige lines show the ECDF of
    FEvals for target value $\Df=10^{-8}$ of all algorithms benchmarked during
    BBOB-2009.
    Right sub-columns: 
    ECDF of FEval ratios of \algorithmA\ divided by \algorithmB for target
    function values $10^k$ with $k$ given in the legend; all
    trial pairs for each function. Pairs where both trials failed are disregarded,
    pairs where one trial failed are visible in the limits being $>0$ or $<1$. The
    legend also indicates, after the colon, the number of functions that were solved in at least one trial
    (\algorithmA\ first).
}
\providecommand{\algorithmA}{DE}
\providecommand{\algorithmB}{PSO DE}
\providecommand{\bbobECDFslegend}[1]{
Bootstrapped empirical cumulative distribution of the number of objective function evaluations divided by dimension (FEvals/DIM) for 50 targets in $10^{[-8..2]}$ for all functions and subgroups in #1-D. The ``best 2009'' line corresponds to the best \ERT\ observed during BBOB 2009 for each single target.
}
\providecommand{\bbobppfigslegend}[1]{
Expected running time (\ERT\ in number of $f$-evaluations 
                as $\log_{10}$ value), divided by dimension for target function value $10^{-8}$ 
                versus dimension. Slanted grid lines indicate quadratic scaling with the dimension. Different symbols correspond to different algorithms given in the legend of #1. Light symbols give the maximum number of function evaluations from the longest trial divided by dimension. Black stars indicate a statistically better result compared to all other algorithms with $p<0.01$ and Bonferroni correction number of dimensions (six).  
Legend: 
{\color{NavyBlue}$\circ$}:\algorithmA
, {\color{red}$\triangledown$}:\algorithmB
}
\providecommand{\bbobppscatterlegend}[1]{
Expected running time (\ERT\ in $\log_{10}$ of number of function evaluations) 
    of \algorithmB\ ($x$-axis) versus \algorithmA\ ($y$-axis) for $46$ target values 
    $\Df \in [100, 10^{-8}]$ in each dimension on functions #1. Markers on the upper or right edge indicate that the respective target
    value was never reached. Markers represent dimension: 
    2:{\color{cyan}+}, 
    3:{\color{green!45!black}$\triangledown$}, 
    5:{\color{blue}$\star$}, 
    10:$\circ$,
    20:{\color{red}$\Box$}, 
    40:{\color{magenta}$\Diamond$}. 
}
\providecommand{\bbobpptablestwolegend}[1]{
%
    Expected running time (ERT in number of function 
    evaluations) divided by the respective best ERT measured during BBOB-2009 in
    dimensions 5 (left) and 20 (right).
    The ERT and in braces, as dispersion measure, the half difference between 90 and 
    10\%-tile of bootstrapped run lengths appear for each algorithm and 
    %
    target, the corresponding best ERT
    in the first row. The different target \Df-values are shown in the top row. 
    \#succ is the number of trials that reached the (final) target $\fopt + 10^{-8}$.
    %
    The median number of conducted function evaluations is additionally given in 
    \textit{italics}, if the target in the last column was never reached. 
    1:\algorithmAshort\ is \algorithmA\ and 2:\algorithmBshort\ is \algorithmB.
    Bold entries are statistically significantly better compared to the other algorithm,
    with $p=0.05$ or $p=10^{-k}$ where $k\in\{2,3,4,\dots\}$ is the number
    following the $\star$ symbol, with Bonferroni correction of #1.
    A $\downarrow$ indicates the same tested against the best algorithm of BBOB-2009.
    
}
\providecommand{\bbobpprldistrlegendtwo}[1]{
%
    Empirical cumulative distributions (ECDF)
    of run lengths and speed-up ratios in 5-D (left) and 20-D (right).
    Left sub-columns: ECDF of
    the number of function evaluations divided by dimension $D$
    (FEvals/D) %
    to reach a target value $\fopt+\Df$ with $\Df=10^{k}$, where
    $k\in\{1, -1, -4, -8\}$ is given by the first value in the legend, for
    \algorithmA\ ($\circ$) and \algorithmB\ ($\triangledown$). Light beige lines show the ECDF of
    FEvals for target value $\Df=10^{-8}$ of all algorithms benchmarked during
    BBOB-2009.
    Right sub-columns: 
    ECDF of FEval ratios of \algorithmA\ divided by \algorithmB for target
    function values $10^k$ with $k$ given in the legend; all
    trial pairs for each function. Pairs where both trials failed are disregarded,
    pairs where one trial failed are visible in the limits being $>0$ or $<1$. The
    legend also indicates, after the colon, the number of functions that were solved in at least one trial
    (\algorithmA\ first).
}
\providecommand{\algorithmA}{PSO DE modified}
\providecommand{\algorithmB}{PSO DE}
\providecommand{\algorithmAshort}{PSO}
\providecommand{\algorithmBshort}{PSO}
\providecommand{\algorithmAshort}{DE}
\providecommand{\algorithmBshort}{PSO}
